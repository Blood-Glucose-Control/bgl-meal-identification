{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junwon (Paul) Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sktime.net/en/stable/api_reference/auto_generated/sktime.annotation.stray.STRAY.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running data preprocessing notebook to use its methods\n",
    "%run \"1.02-vr-ggs-data-preprocessing.ipynb\"  # Use quotes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 2 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\06pau\\AppData\\Local\\Temp\\ipykernel_17084\\1750412534.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(data_dir, file), usecols=columns_to_load, parse_dates=date_parse_columns)\n"
     ]
    }
   ],
   "source": [
    "columns_to_load = [\n",
    "    'date', 'sender_id', 'bgl', 'bgl_date_millis', 'text', 'template', 'msg_type', \n",
    "    'affects_fob', 'affects_iob', 'dose_units', 'food_g', 'food_glycemic_index', \n",
    "    'dose_automatic', 'fp_bgl', 'message_basal_change', '__typename', 'trend'\n",
    "]\n",
    "\n",
    "# Call load_data with specified columns\n",
    "df_list = load_data(\n",
    "    data_dir='../data/raw',  # Replace with your actual directory path\n",
    "    columns_to_load=columns_to_load,\n",
    "    date_parse_columns=['date']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_500030 = df_list[0]\n",
    "df_679372 = df_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use df_500030 for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Meal times and other message times into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_meal_related_events(df):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame to include only rows where 'msg_type' matches specific meal-related events.\n",
    "    \n",
    "    Parameters:\n",
    "    - df : DataFrame, the original DataFrame containing a 'msg_type' column.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df : DataFrame, filtered to include only meal-related events with relevant dates.\n",
    "    \"\"\"\n",
    "    # List of relevant meal-related events\n",
    "    relevant_msg_types = ['ANNOUNCE_MEAL', 'INTERVENTION_SNACK', 'ANNOUNCE_EXERCISE', 'DOSE_INSULIN', 'DOSE_BASAL_INSULIN']\n",
    "    \n",
    "    # Filter DataFrame to include only rows with relevant 'msg_type' values\n",
    "    filtered_df = df[df['msg_type'].isin(relevant_msg_types)].copy()\n",
    "    \n",
    "    # Ensure 'date' column is in datetime format if not already converted\n",
    "    filtered_df['date'] = pd.to_datetime(filtered_df['date'], errors='coerce', utc=True)\n",
    "    \n",
    "    # Drop any rows with invalid or missing dates\n",
    "    filtered_df.dropna(subset=['date'], inplace=True)\n",
    "    \n",
    "    # Sort by date and reset index\n",
    "    filtered_df = filtered_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data frame will help us validate meal times, we can validate our model using this data by checking if selected date is an actual meal time?\n",
    "df_actual = filter_meal_related_events(df_679372) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 32521 entries, 2024-07-01 05:02:39+00:00 to 2024-10-01 04:57:37+00:00\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   sender_id                   32521 non-null  float64\n",
      " 1   bgl                         32521 non-null  float64\n",
      " 2   bgl_date_millis             32521 non-null  float64\n",
      " 3   text                        32521 non-null  object \n",
      " 4   template                    32521 non-null  object \n",
      " 5   affects_fob                 32521 non-null  int64  \n",
      " 6   affects_iob                 32521 non-null  int64  \n",
      " 7   dose_units                  32521 non-null  float64\n",
      " 8   food_g                      32521 non-null  float64\n",
      " 9   food_glycemic_index         32521 non-null  float64\n",
      " 10  dose_automatic              32521 non-null  object \n",
      " 11  fp_bgl                      32521 non-null  float64\n",
      " 12  message_basal_change        32521 non-null  float64\n",
      " 13  __typename                  32521 non-null  object \n",
      " 14  trend                       32521 non-null  object \n",
      " 15  msg_type_ANNOUNCE_EXERCISE  32521 non-null  float64\n",
      " 16  msg_type_ANNOUNCE_MEAL      32521 non-null  float64\n",
      "dtypes: float64(10), int64(2), object(5)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(df_500030).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned and pre processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_679372_processed = preprocess_data(df_679372)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Traning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Identify Relevant Features for STRAY MODEL\n",
    "\n",
    "### Relevant Columns:\n",
    "\n",
    "`bgl`: The main variable representing blood glucose levels, which could show spikes or patterns around meals.\n",
    "\n",
    "`dose_units`: Insulin doses often correlate with meals (especially bolus doses) to manage postprandial glucose levels.\n",
    "\n",
    "`food_g`: The amount of carbohydrates, where non-zero values likely indicate meals or snacks.\n",
    "\n",
    "`food_glycemic_index`: Helps distinguish between regular meals and higher-glycemic foods (like snacks). 0.5 for regular meal announcements, or 1 for INTERVENTION_SNACKS\n",
    "\n",
    "`affects_fob` or `affects_iob`: fob -> food on board, iob -> insuline on board. \n",
    "\n",
    "`trend`: Indicates the direction of blood glucose change rate, which could help capture sharp rises or falls associated with meals.\n",
    "\n",
    "### Improvement:\n",
    "\n",
    "Potentially do a better feature selection, currently I wanted to testout how the STRAY model works with multiple explanatory variables thus I have selected to work with the columns specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_stray(df):\n",
    "    \"\"\"\n",
    "    Prepare the DataFrame by selecting relevant columns for STRAY anomaly detection model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df : DataFrame, the original DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - df_for_stray : DataFrame, with selected columns and necessary preprocessing applied.\n",
    "    \"\"\"\n",
    "    # Select columns that are relevant for detecting meal-related anomalies\n",
    "    df_for_stray = df[['bgl', 'dose_units', 'food_g', 'food_glycemic_index', \n",
    "                       'affects_fob', 'affects_iob', 'trend']]\n",
    "    \n",
    "    # Convert any categorical variables to numeric if needed\n",
    "    # For example, encoding 'trend' as numbers (e.g., FLAT=0, SINGLE_UP=1, etc.)\n",
    "    trend_mapping = {'FLAT': 0, 'SINGLE_UP': 1, 'DOUBLE_UP': 2, 'FORTYFIVE_UP': 3, \n",
    "                     'FORTYFIVE_DOWN': -1, 'DOUBLE_DOWN': -2, 'NOT_COMPUTABLE': None}\n",
    "    df_for_stray['trend'] = df_for_stray['trend'].map(trend_mapping)\n",
    "    \n",
    "    # Drop rows with nulls if necessary\n",
    "    df_for_stray.dropna(inplace=True)\n",
    "    \n",
    "    return df_for_stray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\06pau\\AppData\\Local\\Temp\\ipykernel_17084\\2667450639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_stray['trend'] = df_for_stray['trend'].map(trend_mapping)\n",
      "C:\\Users\\06pau\\AppData\\Local\\Temp\\ipykernel_17084\\2667450639.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_stray.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply to your DataFrame\n",
    "df_for_stray = prepare_data_for_stray(df_679372_processed)  # Replace 'original_df' with your DataFrame variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Train an Apply STRAY for Meal Detection\n",
    "\n",
    "STRAY is typically used to detect outliers, which in this case can signify unusual blood glucose changes related to meals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up STRAY\n",
    "from sktime.annotation.stray import STRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize STRAY for anomaly detection\n",
    "stray_model = STRAY()  # k is a parameter defining the number of neighbors, adjust based on data\n",
    "\n",
    "# Detect anomalies using fit_transform (not fit_predict)\n",
    "anomalies = stray_model.fit_transform(df_for_stray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess_for_meal_labels(df):\n",
    "    \"\"\"\n",
    "    Preprocess the combined DataFrame.\n",
    "    ---\n",
    "    1. Fill NaN values with 0\n",
    "    2. Replace 0 with 'NULL' in the 'msg_type' column\n",
    "    3. One hot encode the 'msg_type' column\n",
    "    4. Drop irrelevant columns for the target variable \n",
    "    (in this case, only keeps 'ANNOUNCE_MEAL', 'INTERVENTION_SNACK', 'ANNOUNCE_EXERCISE', 'DOSE_INSULIN', 'DOSE_BASAL_INSULIN')\n",
    "    5. Drop rows with invalid dates\n",
    "    6. Change affects_fob and affects_iob to 1 and 0\n",
    "    \"\"\"\n",
    "    df = df.fillna(0)\n",
    "    df['msg_type'] = df['msg_type'].replace(0, 'NULL')\n",
    "\n",
    "    # Convert 'date' column to datetime with a custom format\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S%z', errors='coerce', utc=True)\n",
    "    \n",
    "    # Drop rows where the date is null or invalid\n",
    "    df = df.dropna(subset=['date'])\n",
    "    \n",
    "    # Sort by date and handle duplicate timestamps\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Set 'date' as the index\n",
    "    df.set_index('date', inplace=True)\n",
    "    # Change affects_fob and affects_iob to 1 and 0\n",
    "    df['affects_fob'] = df['affects_fob'].apply(lambda x: 1 if x != 0 else 0)\n",
    "    df['affects_iob'] = df['affects_iob'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "    RELEVANT_MSG_TYPES = ['ANNOUNCE_MEAL', 'INTERVENTION_SNACK', 'ANNOUNCE_EXERCISE', 'DOSE_INSULIN', 'DOSE_BASAL_INSULIN']\n",
    "    \n",
    "    encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(df[['msg_type']])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['msg_type']), index=df.index)\n",
    "    \n",
    "    df = df.drop(columns=['msg_type'])\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual = preprocess_for_meal_labels(df_679372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual['msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in the model predictied anomalies\n",
    "df_actual['is_anomaly'] = anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'DOSE_INSULIN', 'DOSE_BASAL_INSULIN', 'TEXT', 'ANNOUNCE_MEAL',\n",
       "       'INTERVENTION_SNACK', 'ANNOUNCE_EXERCISE', 'NEW_PEN', 'NEW_SENSOR',\n",
       "       'BGL_FP_READING', 'MEDICAL_TEST_RESULT'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_679372['msg_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NULL', 'INTERVENTION_SNACK', 'NEW_PEN', 'NEW_SENSOR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual['msg_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual inspection with time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate windoweddetaction (tolerance for anomaly timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust stray model parameters and re-evaluate\n",
    "# testing again with hyper parameter tuning, gradient boost, and cross validation methods\n",
    "# random test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
