{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 2 files.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bgl</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>affects_fob</th>\n",
       "      <th>affects_iob</th>\n",
       "      <th>dose_units</th>\n",
       "      <th>food_g</th>\n",
       "      <th>food_glycemic_index</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01 00:02:39-05:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01 00:07:39-05:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01 00:12:39-05:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01 00:17:39-05:00</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01 00:22:40-05:00</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date    bgl msg_type affects_fob affects_iob  \\\n",
       "0  2024-07-01 00:02:39-05:00   98.0      NaN         NaN         NaN   \n",
       "1  2024-07-01 00:07:39-05:00  100.0      NaN         NaN         NaN   \n",
       "2  2024-07-01 00:12:39-05:00   98.0      NaN         NaN         NaN   \n",
       "3  2024-07-01 00:17:39-05:00   94.0      NaN         NaN         NaN   \n",
       "4  2024-07-01 00:22:40-05:00   94.0      NaN         NaN         NaN   \n",
       "\n",
       "   dose_units  food_g  food_glycemic_index patient_id  \n",
       "0         NaN     NaN                  NaN     500030  \n",
       "1         NaN     NaN                  NaN     500030  \n",
       "2         NaN     NaN                  NaN     500030  \n",
       "3         NaN     NaN                  NaN     500030  \n",
       "4         NaN     NaN                  NaN     500030  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.datatypes import convert_to\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.annotation.ggs import GreedyGaussianSegmentation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def load_data(data_dir='../data/raw'):\n",
    "    \"\"\"\n",
    "    Load all CSV files from the specified directory and concatenate them into a single DataFrame.\n",
    "    \"\"\"\n",
    "    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    columns_to_load = ['date', 'bgl', 'msg_type', 'affects_fob', 'affects_iob', 'dose_units', 'food_g', 'food_glycemic_index']\n",
    "    \n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(data_dir, file), usecols=columns_to_load, parse_dates=['date'])\n",
    "        df['patient_id'] = file.split('_')[0]  # Extract patient ID from filename\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(dataframes, ignore_index=True, axis=0)\n",
    "    # combined_df['date'] = dataframes[0]\n",
    "    print(f\"Loaded data from {len(csv_files)} files.\")\n",
    "    return combined_df\n",
    "\n",
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'msg_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'msg_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m     df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mCOLUMNS_TO_DROP, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 44\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[126], line 13\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mPreprocess the combined DataFrame.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m---\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m5. Drop rows with invalid dates\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsg_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmsg_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNULL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert 'date' column to datetime with a custom format\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m, utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'msg_type'"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the combined DataFrame.\n",
    "    ---\n",
    "    1. Fill NaN values with 0\n",
    "    2. Replace 0 with 'NULL' in the 'msg_type' column\n",
    "    3. One hot encode the 'msg_type' column\n",
    "    4. Drop irrelevant columns for the target variable \n",
    "    (in this case, only keeps 'ANNOUNCE_MEAL', 'INTERVENTION_SNACK', 'ANNOUNCE_EXERCISE', 'DOSE_INSULIN', 'DOSE_BASAL_INSULIN')\n",
    "    5. Drop rows with invalid dates\n",
    "    \"\"\"\n",
    "    df = df.fillna(0)\n",
    "    df['msg_type'] = df['msg_type'].replace(0, 'NULL')\n",
    "\n",
    "    # Convert 'date' column to datetime with a custom format\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S%z', errors='coerce', utc=True)\n",
    "    \n",
    "    # Drop rows where the date is null or invalid\n",
    "    df = df.dropna(subset=['date'])\n",
    "    \n",
    "    # Sort by date and handle duplicate timestamps\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Handle duplicate timestamps by adding a small time increment\n",
    "    df['date'] = df.groupby('date').cumcount().add(1).astype('timedelta64[ms]') + df['date']\n",
    "    \n",
    "    # Set 'date' as the index\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    RELEVANT_MSG_TYPES = ['ANNOUNCE_MEAL', 'INTERVENTION_SNACK', 'ANNOUNCE_EXERCISE', 'DOSE_INSULIN', 'DOSE_BASAL_INSULIN']\n",
    "    \n",
    "    encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(df[['msg_type']])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['msg_type']), index=df.index)\n",
    "    \n",
    "    df = df.drop(columns=['msg_type'])\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "    COLUMNS_TO_DROP = [col for col in df.columns if 'msg_type' in col and not any(msg_type in col for msg_type in RELEVANT_MSG_TYPES)]\n",
    "    df.drop(columns=COLUMNS_TO_DROP, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess_data(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during fitting: 'float' object has no attribute 'shape'\n",
      "X_nested shape: (71695, 6)\n",
      "X_nested dtypes: 0    object\n",
      "1    object\n",
      "2    object\n",
      "3    object\n",
      "4    object\n",
      "5    object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Use the function\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m segmentation, X_nested \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_gaussian_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m X_nested\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# visualize_segmentation(X_nested, segmentation)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#     print(f\"An error occurred: {e}\")\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#     print(f\"DataFrame shape: {df.shape}\")\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#     print(f\"DataFrame columns: {df.columns}\")\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#     print(f\"DataFrame dtypes: {df.dtypes}\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[152], line 28\u001b[0m, in \u001b[0;36mgreedy_gaussian_segmentation\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     segmentation \u001b[38;5;241m=\u001b[39m \u001b[43msegmenter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_nested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during fitting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\sktime\\annotation\\ggs.py:544\u001b[0m, in \u001b[0;36mGreedyGaussianSegmentation.fit_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mArrayLike:\n\u001b[0;32m    527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform segmentation.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m        labels for each of the data points.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\sktime\\annotation\\base\\_base.py:179\u001b[0m, in \u001b[0;36mBaseSeriesAnnotator.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    175\u001b[0m X \u001b[38;5;241m=\u001b[39m check_series(X)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# fkiraly: insert checks/conversions here, after PR #1012 I suggest\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\sktime\\annotation\\ggs.py:517\u001b[0m, in \u001b[0;36mGreedyGaussianSegmentation._predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX must not have more than two dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adaptee\u001b[38;5;241m.\u001b[39minitialize_intermediates()\n\u001b[1;32m--> 517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchange_points_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_change_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (start, stop) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchange_points_[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchange_points_[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    522\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\sktime\\annotation\\ggs.py:333\u001b[0m, in \u001b[0;36mGGS.find_change_points\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    331\u001b[0m change_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentity_segmentation(data)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intermediate_change_points \u001b[38;5;241m=\u001b[39m [change_points[:]]\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intermediate_ll \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumulative_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchange_points\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Start GGS Algorithm\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_max):\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\sktime\\annotation\\ggs.py:174\u001b[0m, in \u001b[0;36mGGS.cumulative_log_likelihood\u001b[1;34m(self, data, change_points)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, stop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(change_points[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], change_points[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[0;32m    173\u001b[0m     segment \u001b[38;5;241m=\u001b[39m data[start:stop, :]\n\u001b[1;32m--> 174\u001b[0m     log_likelihood \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\sktime\\annotation\\ggs.py:143\u001b[0m, in \u001b[0;36mGGS.log_likelihood\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the GGS log-likelihood of the segmented Gaussian model.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03mlog_likelihood\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m nrows, ncols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 143\u001b[0m cov \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m (_, logdet) \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mslogdet(\n\u001b[0;32m    145\u001b[0m     cov \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamb) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(ncols) \u001b[38;5;241m/\u001b[39m nrows\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nrows \u001b[38;5;241m*\u001b[39m logdet \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamb) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[0;32m    149\u001b[0m     np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(cov \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamb) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(ncols) \u001b[38;5;241m/\u001b[39m nrows)\n\u001b[0;32m    150\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2749\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2746\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2747\u001b[0m         w \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m aweights\n\u001b[1;32m-> 2749\u001b[0m avg, w_sum \u001b[38;5;241m=\u001b[39m \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2750\u001b[0m w_sum \u001b[38;5;241m=\u001b[39m w_sum[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2752\u001b[0m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\bg_control\\0_meal_identification\\meal_identification\\venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:577\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[0;32m    573\u001b[0m     avg \u001b[38;5;241m=\u001b[39m avg_as_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(a, wgt,\n\u001b[0;32m    574\u001b[0m                       dtype\u001b[38;5;241m=\u001b[39mresult_dtype)\u001b[38;5;241m.\u001b[39msum(axis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeepdims_kw) \u001b[38;5;241m/\u001b[39m scl\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m returned:\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m!=\u001b[39m avg_as_array\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m    578\u001b[0m         scl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(scl, avg_as_array\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg, scl\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def greedy_gaussian_segmentation(df):\n",
    "    \"\"\"\n",
    "    Perform greedy Gaussian segmentation on the DataFrame using sktime's GreedyGaussianSegmentation.\n",
    "    \"\"\"\n",
    "    # Separate X and y\n",
    "    X = df.drop(columns=[col for col in df.columns if 'msg_type' in col or 'patient_id' in col])\n",
    "\n",
    "    # Ensure X is not empty\n",
    "    if X.empty:\n",
    "        raise ValueError(\"X is empty after dropping columns. Check your column names and filtering.\")\n",
    "\n",
    "    # Convert X to the required format for sktime\n",
    "    X_2d = X.values\n",
    "\n",
    "    X_nested = from_2d_array_to_nested(X_2d, index=X.index)\n",
    "\n",
    "    # Ensure X_nested is not empty and has the correct shape\n",
    "    if X_nested.empty or X_nested.shape[1] == 0:\n",
    "        raise ValueError(\"X_nested is empty or has no columns. Check the conversion process.\")\n",
    "\n",
    "    # Initialize and fit the segmentation model\n",
    "    segmenter = GreedyGaussianSegmentation(k_max=10)  # Adjust k_max as needed\n",
    "    \n",
    "    # Fit the model\n",
    "    try:\n",
    "        segmentation = segmenter.fit_predict(X_nested)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during fitting: {e}\")\n",
    "        print(f\"X_nested shape: {X_nested.shape}\")\n",
    "        print(f\"X_nested dtypes: {X_nested.dtypes}\")\n",
    "        raise\n",
    "\n",
    "    return segmentation, X_nested\n",
    "\n",
    "def visualize_segmentation(X_nested, segmentation, column_name='bgl'):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot the time series\n",
    "    plt.plot(X_nested.index, X_nested[column_name].values.flatten(), label=column_name)\n",
    "    \n",
    "    # Plot segmentation\n",
    "    for start, end in zip(segmentation[:-1], segmentation[1:]):\n",
    "        plt.axvline(X_nested.index[start], color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.title(f'{column_name} Over Time with Segmentation')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(column_name)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use the function\n",
    "# try:\n",
    "segmentation, X_nested = greedy_gaussian_segmentation(df)\n",
    "X_nested.head()\n",
    "# visualize_segmentation(X_nested, segmentation)\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "#     print(f\"DataFrame shape: {df.shape}\")\n",
    "#     print(f\"DataFrame columns: {df.columns}\")\n",
    "#     print(f\"DataFrame dtypes: {df.dtypes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
